@cindex IEEE floating point 

This chapter describes functions for examing the representation of
floating point numbers and controlling the floating point environment of
your program.

@c to turn on math exception handling use __setfpucw, see
@c /usr/include/i386/fpu_control.h
@c e.g.
@c #include <math.h>
@c #include <stdio.h>
@c #include <fpu_control.h>
@c double f (double x) ;
@c int main ()
@c {
@c   double a = 0 ;
@c   double y, z ;
@c   __setfpucw(0x1372); 
@c mention extended vs double precision on Pentium, and how to get around
@c it (-ffloat-store, or selective use of volatile)

@menu
* Representation of floating point numbers::  
* Setting up your IEEE environment::  
@end menu

@node Representation of floating point numbers
@section Representation of floating point numbers

@deftypefun void gsl_ieee_printf_float (const float * @var{x})
@deftypefunx void gsl_ieee_printf_double (const double * @var{x})

@end deftypefun

@example
#include <stdio.h>
#include <gsl_ieee_utils.h>

main () 
@{
  float f = 1.0/3.0 ;
  double d = 1.0/3.0 ;

  double fd = f ; /* promote from float to double */
  
  printf("     float 1/3 = ") ; gsl_ieee_printf_float(&f) ; printf("\n") ;
  printf("promoted float = ") ; gsl_ieee_printf_double(&fd) ; printf("\n") ;
  printf("    double 1/3 = ") ; gsl_ieee_printf_double(&d) ; printf("\n") ;
@}
@end example


@example
     float 1/3 =  1.01010101010101010101011*2^-2
promoted float =  1.0101010101010101010101100000000000000000000000000000*2^-2
    double 1/3 =  1.0101010101010101010101010101010101010101010101010101*2^-2
@end example

To use these numbers in Calc, precede them by @code{2#} to indicate binary.
In @code{bc}, work with the mantissa separately from the exponent.

float vs double vs long double (how many digits are available for each)

importance of using 1.234L in long double calculations

@example
int main (void)
@{
  long double x = 1.0, y = 1.0 ;
  
  x = x + 0.2 ;
  y = y + 0.2L ;

  printf(" d %.20Lf\n",x) ;
  printf("ld %.20Lf\n",y) ;

  return 1;
@}

 d 1.20000000000000001110
ld 1.20000000000000000004
@end example


@node Setting up your IEEE environment
@section Setting up your IEEE environment

The IEEE standard defines several @dfn{modes} for controlling the
behavior of floating point operations. These modes specify the important
properties of computer arithmetic: the direction used for rounding (e.g.
whether numbers should be rounded up, down or to the nearest number),
the rouding precision and how the program should handle arithmetic
exceptions, such as division by zero.

Unfortunately there is no universal API for controlling these features --
each system has its own way of accessing them.  For example, the Linux
kernel provides the function @code{__setfpucw}
(@dfn{set-fpu-control-word}) to set IEEE modes, while HP-UX and Solaris
use the functions @code{fpsetround} and @code{fpsetmask}. To help you
write portable programs GSL allows you to specify modes in a
platform-independent using the environment variable
@code{GSL_IEEE_MODE}.  The library then takes care of all the necessary
machine-specific initializations for you when you call the function
@code{gsl_ieee_env_setup}.


@deftypefun void gsl_ieee_env_setup ()
This function reads the environment variable @code{GSL_IEEE_MODE} and
attempts to set up the corresponding specified IEEE modes.  The
environment variable should be a list of keywords, separated by
semicolons, like this,

@display
@code{GSL_IEEE_MODE} = "@var{keyword};@var{keyword};..."
@end display
@noindent
where @var{keyword} is one of the following mode-names,

@itemize @asis
@item 
@code{single-precision}
@item 
@code{double-precision}
@item 
@code{extended-precision}
@item 
@code{round-to-nearest}
@item 
@code{round-down}
@item 
@code{round-up}
@item 
@code{round-to-zero}
@item 
@code{mask-all}
@item 
@code{mask-invalid}
@item 
@code{mask-denormalized}
@item 
@code{mask-division-by-zero}
@item 
@code{mask-overflow}
@item 
@code{mask-underflow}
@item 
@code{trap-inexact}
@item 
@code{trap-common}
@end itemize

If @code{GSL_IEEE_MODE} is empty or undefined then the function returns
immediately and no attempt is made to change the system's IEEE
mode. When the modes from @code{GSL_IEEE_MODE} are turned on the
function prints a short message showing the new settings to remind you
that the results of the program will be affected.

If the requested modes are not supported by the platform being used then
the function calls the error handler and returns an error code of
@code{GSL_EUNSUP}.

@end deftypefun

To demonstrate the effects of different rounding modes consider
following the program computes @math{e}, the base of natural logarithms,
by summing a rapidly-decreasing series,

@equation
e = 1 + @{1 \over 2!@} + @{1 \over 3!@} + @{1 \over 4!@} + \dots 
  = 2.71828182846...
@end equation

        
@example
#include <math.h>
#include <stdio.h>
#include <gsl_ieee_utils.h>

int main (void)
@{
  double x = 1, oldsum = 0, sum = 0; 
  int i = 0 ;

  gsl_ieee_env_setup () ; /* read GSL_IEEE_MODE */

  do 
    @{
      i++ ;
      
      oldsum = sum ;
      sum += x ;
      x = x / i ;
      
      printf("i=%2d sum=%.18f error=%g\n",i, sum, sum - M_E) ;
    @}  
  while (sum != oldsum) ;

@}
@end example
@noindent
Here are the results of running the program in @code{round-to-nearest}
mode. This is the IEEE default so it isn't really necessary to specify
it here,
@example
GSL_IEEE_MODE="round-to-nearest" ./a.out 
i= 1 sum=1.000000000000000000 error=-1.71828
i= 2 sum=2.000000000000000000 error=-0.718282
....
i=18 sum=2.718281828459045535 error=4.44089e-16
i=19 sum=2.718281828459045535 error=4.44089e-16
@end example
@noindent
After nineteen terms the sum converges to within @math{4 \times
10^@{-16@}} of the correct value.  If we now change the rounding mode to
@code{round-down} the final result is less accurate,

@example
GSL_IEEE_MODE="round-down" ./a.out 
i= 1 sum=1.000000000000000000 error=-1.71828
....
i=19 sum=2.718281828459041094 error=-3.9968e-15
@end example
@noindent
The result is about @math{4 \times 10^@{-15@}} below the correct value, an
order of magnitude worse than the result obtained in the
@code{round-to-nearest} mode.

If we change to rounding mode to @code{round-up} then the series no
longer converges (the reason is that when we add each term to the sum
the final result is always rounded up. This is guaranteed to increase the sum
by at least one tick on each iteration). To avoid this problem we would
need to use a safer converge criterion, such as @code{while (fabs(sum -
oldsum) > epsilon)}, with a suitably chosen value of epsilon.

Finally we can see the effect of computing the sum using
single-precision rounding, in the default @code{round-to-nearest}
mode. In this case the program thinks it is still using double precision
numbers but the CPU rounds the result of each floating point operation
to single-precision accuracy. This simulates the effect of writing the
program using single-precision @code{float} variables instead of
@code{double} variables. The iteration stops after about half the number
of iterations and the final result is much less accurate,

@example
GSL_IEEE_MODE="single-precision" ./a.out 
....
i=12 sum=2.718281984329223633 error=1.5587e-07
@end example
@noindent
with an error of @math{O(10^@{-7@})}, which corresponds to single
precision accuracy (about 1 part in @math{10^7}). Continuing the
iterations further does not decrease the error because all the
subsequent results are rounded to the same value.

@node IEEE References and Further Reading
@section IEEE References and Further Reading

@itemize @asis
@item
David Goldberg: What Every Computer Scientist Should Know About
Floating-Point Arithmetic. [Comm ACM ??] Vol. 23, No. 1 (March 1991) pages 5-48
@end itemize
@noindent
