@cindex fitting
@cindex least squares fit
@cindex regression, least squares

This chapter describes functions for performing least squares fits to
experimental data. The data may be weighted or unweighted.  For weighted
data the functions compute the best fit parameters and their associated
covariance matrix.  For unweighted data the covariance matrix is
estimated from the scatter of the points, giving a variance-covariance
matrix. The functions are divided into separate versions for simple one-
or two-parameter regression and multiple-parameter fits.

@menu
* Simple linear fitting::       
* Linear fitting without a constant term::  
* Multi-parameter fitting::     
* Fitting examples::            
* Fitting References and Further Reading::  
@end menu

@node  Simple linear fitting
@section Simple linear fitting

The functions described in this section can be used to perform
least-squares fits to a straight line model, @math{Y = c_0 + c_1 X}.
For weighted data the best-fit is found by minimizing the weighted sum of
squared residuals, @math{\chi^2},

@tex
\beforedisplay
$$
\chi^2 = \sum_i w_i (y_i - (c_0 + c_1 x_i))^2
$$
\afterdisplay
@end tex
@ifinfo
@example
\chi^2 = \sum_i w_i (y_i - (c_0 + c_1 x_i))^2
@end example
@end ifinfo

@noindent
for the parameters @math{c_0}, @math{c_1}.  For unweighted data the
sum is computed with @math{w_i = 1}.

@deftypefun int gsl_fit_linear (const double * @var{x}, const size_t @var{xstride}, const double * @var{y}, const size_t @var{ystride}, size_t @var{n}, double * @var{c0}, double * @var{c1}, double * @var{cov00}, double * @var{cov01}, double * @var{cov11}, double * @var{sumsq})
This function computes the best-fit linear regression coefficients
(@var{c0},@var{c1}) of the model @math{Y = c_0 + c_1 X} for the datasets
(@var{x}, @var{y}), two vectors of length @var{n} with strides
@var{xstride} and @var{ystride}.  The variance-covariance matrix for the
parameters (@var{c0}, @var{c1}) is estimated from the scatter of the
points around the best-fit line and returned via the parameters
(@var{cov00}, @var{cov01}, @var{cov11}).  The sum of squares of the
residuals from the best-fit line is returned in @var{sumsq}.
@end deftypefun

@deftypefun int gsl_fit_wlinear (const double * @var{x}, const size_t @var{xstride}, const double * @var{w}, const size_t @var{wstride}, const double * @var{y}, const size_t @var{ystride}, size_t @var{n}, double * @var{c0}, double * @var{c1}, double * @var{cov00}, double * @var{cov01}, double * @var{cov11}, double * @var{chisq})
This function computes the best-fit linear regression coefficients
(@var{c0},@var{c1}) of the model @math{Y = c_0 + c_1 X} for the weighted
datasets (@var{x}, @var{y}), two vectors of length @var{n} with strides
@var{xstride} and @var{ystride}.  The vector @var{w}, of length @var{n}
and stride @var{wstride}, specifies the weight of each datapoint. The
weight is the reciprocal of the variance for each datapoint in @var{y}.

The covariance matrix for the parameters (@var{c0}, @var{c1}) is
estimated from weighted data and returned via the parameters
(@var{cov00}, @var{cov01}, @var{cov11}).  The weighted sum of squares of
the residuals from the best-fit line, @math{\chi^2}, is returned in
@var{chisq}.
@end deftypefun

@deftypefun int gsl_fit_linear_est (double @var{x}, double @var{c0}, double @var{c1}, double @var{c00}, double @var{c01}, double @var{c11}, double *@var{y}, double *@var{y_err})
This function uses the best-fit linear regression coefficients
@var{c0},@var{c1} and their estimated covariance
@var{cov00},@var{cov01},@var{cov11} to compute the fitted function
@var{y} and its standard deviation @var{y_err} for the model @math{Y =
c_0 + c_1 X} at the point @var{x}.
@end deftypefun

@node Linear fitting without a constant term
@section Linear fitting without a constant term

The functions described in this section can be used to perform
least-squares fits to a straight line model without a constant term,
@math{Y = c_1 X}.  For weighted data the best-fit is found by minimizing
the weighted sum of squared residuals, @math{\chi^2},

@tex
\beforedisplay
$$
\chi^2 = \sum_i w_i (y_i -  c_1 x_i)^2
$$
\afterdisplay
@end tex
@ifinfo
@example
\chi^2 = \sum_i w_i (y_i - c_1 x_i)^2
@end example
@end ifinfo

@noindent
for the parameter @math{c_1}.  For unweighted data the sum is
computed with @math{w_i = 1}.

@deftypefun int gsl_fit_mul (const double * @var{x}, const size_t @var{xstride}, const double * @var{y}, const size_t @var{ystride}, size_t @var{n}, double * @var{c1}, double * @var{cov11}, double * @var{sumsq})
This function computes the best-fit linear regression coefficient
@var{c1} of the model @math{Y = c_1 X} for the datasets (@var{x},
@var{y}), two vectors of length @var{n} with strides @var{xstride} and
@var{ystride}.  The variance of the parameter @var{c1} is estimated from
the scatter of the points around the best-fit line and returned via the
parameter @var{cov11}.  The sum of squares of the residuals from the
best-fit line is returned in @var{sumsq}.
@end deftypefun

@deftypefun int gsl_fit_wmul (const double * @var{x}, const size_t @var{xstride}, const double * @var{w}, const size_t @var{wstride}, const double * @var{y}, const size_t @var{ystride}, size_t @var{n}, double * @var{c1}, double * @var{cov11}, double * @var{sumsq})
This function computes the best-fit linear regression coefficient
@var{c1} of the model @math{Y = c_1 X} for the weighted datasets
(@var{x}, @var{y}), two vectors of length @var{n} with strides
@var{xstride} and @var{ystride}.  The vector @var{w}, of length @var{n}
and stride @var{wstride}, specifies the weight of each datapoint. The
weight is the reciprocal of the variance for each datapoint in @var{y}.

The variance of the parameter @var{c1} is estimated from the weighted
data and returned via the parameters @var{cov11}.  The weighted sum of
squares of the residuals from the best-fit line, @math{\chi^2}, is
returned in @var{chisq}.
@end deftypefun

@deftypefun int gsl_fit_mul_est (double @var{x}, double @var{c1}, double @var{c11}, double *@var{y}, double *@var{y_err})
This function uses the best-fit linear regression coefficient @var{c1}
and its estimated covariance @var{cov11} to compute the fitted function
@var{y} and its standard deviation @var{y_err} for the model @math{Y =
c_1 X} at the point @var{x}.
@end deftypefun

@node Multi-parameter fitting
@section Multi-parameter fitting

The functions described in this section perform least-squares fits to a
general linear model, @math{y = X c} where @math{y} is a vector of
@math{n} observations, @math{X} is an @math{n} by @math{p} matrix of
predictor variables, and @math{c} are the @math{p} unknown best-fit
parameters, which are to be estimated.

The best-fit is found by minimizing the weighted sums of squared
residuals, @math{\chi^2},

@tex
\beforedisplay
$$
\chi^2 = (y - X c)^T W (y - X c)
$$
\afterdisplay
@end tex
@ifinfo
@example
\chi^2 = (y - X c)^T W (y - X c)
@end example
@end ifinfo
@noindent
with respect to the parameters @math{c}. The weights are specified by
the diagonal elements of the @math{n} by @math{n} matrix @math{W}.  For
unweighted data @math{W} is replaced by the identity matrix.

This formulation can be used for fits to any number of functions and/or
variables by preparing the matrix @math{X} appropriately.  For example,
to fit to a @math{p}-th order polynomial in @var{x}, use the following
matrix

@tex
\beforedisplay
$$
X_{ij} = x_i^j
$$
\afterdisplay
@end tex
@ifinfo
@example
X_@{ij@} = x_i^j
@end example
@end ifinfo
@noindent
To fit to a set of @math{p} sinusoidal functions with fixed frequencies
@math{\omega_1}, @math{\omega_2}, @dots{}, @math{\omega_p}, use,

@tex
\beforedisplay
$$
X_{ij} = \sin(\omega_j x_i)
$$
\afterdisplay
@end tex
@ifinfo
@example
X_@{ij@} = sin(\omega_j x_i)
@end example
@end ifinfo
@noindent
To fit to @math{p} independent variables @math{x_1}, @math{x_2}, @dots{},
@math{x_p}, use

@tex
\beforedisplay
$$
X_{ij} = x_j(i)
$$
\afterdisplay
@end tex
@ifinfo
@example
X_@{ij@} = x_j(i)
@end example
@end ifinfo
@noindent
where @math{x_j(i)} is the @math{i}-th value of the predictor variable
@math{x_j}.

The solution of the general linear least-squares system requires an
additional working space for intermediate results, such as the singular
value decomposition of the matrix @math{X}.

@deftypefun {gsl_multifit_linear_workspace *} gsl_multifit_linear_alloc (size_t @var{n}, size_t @var{p})
This function allocates a workspace for fitting a model to @var{n}
observations using @var{p} parameters.
@end deftypefun

@deftypefun void gsl_multifit_linear_free (gsl_multifit_linear_workspace * @var{work})
This function frees the memory associated with the workspace @var{w}.
@end deftypefun

@deftypefun int gsl_multifit_linear (const gsl_matrix * @var{X}, const gsl_vector * @var{y}, gsl_vector * @var{c}, gsl_matrix * @var{cov}, double * @var{chisq}, gsl_multifit_linear_workspace * @var{work})
This function computes the best-fit parameters @var{c} of the model
@math{y = X c} for the observations @var{y} and the matrix of predictor
variables @var{X}.  The variance-covariance matrix of the model
parameters @var{cov} is estimated from the scatter of the observations
about the best-fit.  The sum of squares of the residuals from the
best-fit, @math{\chi^2}, is returned in @var{chisq}. 

The best-fit is found by singular value decomposition of the matrix
@var{X} using the preallocated workspace provided in @var{work}. Any
components which have zero singular value (to machine precision) are
discarded from the fit.
@end deftypefun

@deftypefun int gsl_multifit_wlinear (const gsl_matrix * @var{X}, const gsl_vector * @var{w}, const gsl_vector * @var{y}, gsl_vector * @var{c}, gsl_matrix * @var{cov}, double * @var{chisq}, gsl_multifit_linear_workspace * @var{work})

This function computes the best-fit parameters @var{c} of the model
@math{y = X c} for the observations @var{y} and the matrix of predictor
variables @var{X}.  The covariance matrix of the model parameters
@var{cov} is estimated from the weighted data.  The weighted sum of
squares of the residuals from the best-fit, @math{\chi^2}, is returned
in @var{chisq}.

The best-fit is found by singular value decomposition of the matrix
@var{X} using the preallocated workspace provided in @var{work}. Any
components which have zero singular value (to machine precision) are
discarded from the fit.
@end deftypefun

@node Fitting examples
@section Examples

The following program computes a least squares straight-line fit to a
simple (fictitious) dataset, and outputs the best-fit line and its
associated one standard-deviation error bars.

@example
#include <stdio.h>
#include <gsl/gsl_fit.h>

int
main ()
@{
  int i, n = 4;
  double x[4] = @{ 1970, 1980, 1990, 2000 @};
  double y[4] = @{   12,   11,   14,   13 @};
  double w[4] = @{  0.1,  0.2,  0.3,  0.4 @};

  double c0, c1, cov00, cov01, cov11, chisq;

  gsl_fit_wlinear (x, 1, w, 1, y, 1, n, 
                   &c0, &c1, &cov00, &cov01, &cov11, 
                   &chisq);

  printf("# best fit: Y = %g + %g X\n", c0, c1);
  printf("# covariance matrix:\n");
  printf("# [ %g, %g\n#   %g, %g]\n", cov00, cov01, cov01, cov11);
  printf("# chisq = %g\n", chisq);

  for (i = 0; i < n; i++)
    printf("data: %g %g %g\n", x[i], y[i], 1/sqrt(w[i]));

  printf("\n");

  for (i = -30 ; i < 130 ; i++)
    @{
      double xf = x[0] + (i/100.0) * (x[n-1] - x[0]);
      double yf, yf_err;

      gsl_fit_linear_est (xf, c0, c1, cov00, cov01, cov11, &yf, &yf_err);

      printf("fit: %g %g\n", xf, yf);
      printf("hi : %g %g\n", xf, yf + yf_err);
      printf("lo : %g %g\n", xf, yf - yf_err);
    @}
@}
@end example
@noindent
The following commands extract the data from the output of the program
and display it using the @sc{gnu} plotutils @code{graph} utility, 

@example
$ ./demo > tmp
$ more tmp
# best fit: Y = -106.6 + 0.06 X
# covariance matrix:
# [ 39602, -19.9
#   -19.9, 0.01]
# chisq = 0.8

$ for n in data fit hi lo ; do grep "^$n" tmp | cut -d: -f2 > $n ; done
$ graph -T X -X x -Y y -y 0 20 -m 0 -S 2 -Ie data 
     -S 0 -I a -m 1 fit -m 2 hi -m 2 lo
@end example

@iftex
@sp 1
@center @image{fit-wlinear,4in}
@end iftex

@node Fitting References and Further Reading
@section References and Further Reading

A summary of formulas and techniques for least squares fitting can be
found in the "Statistics" chapter of the Annual Review of Particle
Physics prepared by the Particle Data Group.

@itemize @asis
@item
@cite{Review of Particle Properties}
R.M. Barnett et al., Physical Review D54, 1 (1996)
@end itemize
@noindent
The Review of Particle Physics is available online at
@url{http://pdg.lbl.gov/}.

The tests used to prepare these routines are based on the NIST
Statistical Reference Datasets. The datasets and their documentation are
available from @url{http://www.nist.gov/itl/div898/strd/index.html}


