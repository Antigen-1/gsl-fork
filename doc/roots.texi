@cindex root finding
@cindex zero finding
@cindex finding roots
@cindex finding zeros
@cindex roots
@cindex solving a non-linear equation

This chapter describes functions for finding a root of an arbitrary
one-dimensional function which you provide.  The header file
@file{gsl_roots.h} contains prototypes for the root finding functions
and related declarations.

@menu
* Root Finding Overview::       
* Root Finder Exit Values::     
* Providing the Function to Search::  
* Search Bounds and Guesses::   
* Search Stopping Parameters::  
* Bisection::                   
* Brent-Dekker Method::         
* False Position::              
* Secant Method::               
* Newtons Method::              
* Root Finder Error Handling::  
@end menu

@node Root Finding Overview
@section Root Finding Overview
@cindex root finding, overview

Root finding algorithms can be divided into two classes, those which are
guaranteed to converge and those which converge only if started "close
enough" to a root.  Algorithms with guaranteed convergence start with a
bounded region known to contain a root. The size of this bounded region
is reduced iteratively until it is reaches a desired tolerance. This
provides a rigorous error estimate for the location of the root. 

Algorithms without guaranteed convergence sacrifice rigorous error
bounds for speed.  By approximating the behavior of a function in the
vicinity of a root they attempt to find a higher order improvement of an
initial guess.  This technique is often referred to as "root
polishing". When the behavior of the function is known to be compatible
with the algorithm and a good initial guess is available, perhaps from a
systematic approximation, these algorithms can provide rapid
convergence.

Note that root finding functions can only search for one root at a time.
When there are several roots in the search area, the first root to be
found will be returned; however it is difficult to predict which of the
roots this will be. @emph{In most cases, no error will be reported if
you try to find a root in an area where there is more than one.}

Care must be taken when a function may have a root of second-order or
higher multiplicity (such as @math{f(x) = (x-c)^2} or @math{f(x) =
(x-c)^3}).  Routines which maintain a strict bound on the root should
not have problems with odd-multiplicity roots (e.g. cubic, quintic,
@dots{}), since they make use only of the occurrence zero-crossings and
not the behavior of the function. However it is impossible to use these
routines for even-multiplicity roots because they require a bound on the
initial root which guarantees a zero-crossing (below zero at one end of
the bound and above zero at the other end). Roots with even-multiplicity
do not cross zero, but only touch it instantaneously. In general these
functions need to be approached on a case-by-case basis using knowledge
of the algorithm to be used. Root polishing algorithms generally work
with higher multiplicity roots but with a reduced rate of convergence.

While it is not absolutely required that @math{f} have a root within the
search region, numerical root finding functions should not be used
haphazardly to check for the @emph{existence} of roots. There are better
ways to do this! Because it is so easy to create situations where
numerical root finders go awry, it is a bad idea to throw a root finder
at a function you do not know much about. In general it is best to
examine the function visually by plotting before searching for a root.

@node Root Finder Exit Values
@section Root Finder Exit Values

Since the return value of the root finding functions is reserved for the
error status, you must provide storage for the location of the found
root. 

@deftypevr {Function Argument} {double *} root
@vindex @r{root finding,} root @r{(function argument)}
A pointer to a place for the root finder to store the location of the
found root. This must be a valid pointer; the root finders will not
allocate any memory for you.
@end deftypevr

If a root finder succeeds, it will return @code{0} and store the
location of the found root in @code{*root}.

If a root finder fails, it will return @code{-1} and set
@code{gsl_errno} to a diagnostic value. @xref{Root Finder Error
Handling}, for a discussion of possible error codes. Nothing useful will
be stored in @code{*root} if the function failed.


@node Providing the Function to Search
@section Providing the Function to Search
@cindex root finding, providing a function to search

You must provide a continous function of one variable for the root
finder(s) to operate on, and, sometimes, its first derivative.

Recall that when passing pointers to functions, you give the name of the
function you are passing. For example:

@smallexample
foo = i_take_a_function_pointer(my_function);
@end smallexample

@deftypevr {Function Argument} double {@t{(*} f@t{)(double)}}
@vindex @r{root finding,} f @r{(function argument)}
A pointer to the function whose root you are searching for. It is called
by the root finding function many times during its search. It must be
continous within the region of interest.

Here is an example function which you could pass to a root finder:

@smallexample
@group
double
my_f (double x) @{
   return sin (2 * x) + 2 * cos (x);
@}
@end group
@end smallexample

@end deftypevr

@deftypevr {Function Argument} double {@t{(*} df@t{)(double)}}
@vindex @r{root finding,} df @r{(function argument)}
A pointer to the first derivative of the function whose root you are
searching for.

If we were looking for a root of the function in the previous example,
this is what we would use for @code{df}:

@smallexample
@group
double
my_df (double x) @{
   return 2 * cos (2 * x) - 2 * sin (x);
@} 
@end group
@end smallexample

@end deftypevr

@deftypevr {Function Argument} void {@t{(*} fdf@t{)(double *, double *, double, int, int)}}
A pointer to a function which calculates both the value of the function
under search and the value of its first derivative. Because many terms
of a function and its derivative are the same, it is often faster to use
this method as opposed to providing @math{f(x)} and @math{f'(x)}
separately. However, it is more complicated.

It stores @math{f(x)} in its first argument and @math{f'(x)} in its
second.

Here's an example where @math{f(x) = 2\sin(2x)\cos(x)}:

@smallexample
@group
void
my_fdf (double * y, double * yprime, double x,
        int y_wanted, int yprime_wanted) @{
   double sin2x, cosx;

   sin2x = sin (2 * x);
   cosx = cos (x);

   if (y_wanted)
      *y = 2 * sin2x * cos (x);
   if (yprime_wanted)
      *yprime = 2 * sin2x * -sin (x) + 2 * cos (2 * x) * cosx);
@}
@end group
@end smallexample

@end deftypevr

 Low level functions return errors and roots and are provided functions
to search in the same manner as the high level functions; see @ref{Root
Finder Exit Values}, and @ref{Providing the Function to Search},
respectively.

@node Search Bounds and Guesses
@section Search Bounds and Guesses
@cindex root finding, search bounds
@cindex root finding, guess(es)

When using low level functions, you can specify and monitor the region
being searched more precisely than you can when using high level
functions. You provide either search bounds or one or two guesses; this
section explains how search bounds and guesses work and how function
arguments control them.

Search bounds are the endpoints of the search interval which is iterated
smaller and smaller until the length of the interval is smaller than the
requested precision or one of the endpoints converges; a guess is an
@math{x} value which is iterated around until the it is within the
desired precision of a root. Two guesses behave similarly to one; there
are just two @math{x} values wandering about instead of one.

In low level functions, these arguments are defined as pointers to
@code{double} rather than simply @code{double}s for two reasons. First,
if the root finding function fails, it is very useful to have the final
values of your iterated variables available to help diagnose why it
failed. Second, it makes it possible to preserve the state of the root
finder, enabling it to be restarted in the same place if needed. A
situation where this could be useful is if the function under search is
very costly to evaluate. 

Note that these arguments must be valid pointers; the root finders will
not allocate any memory for you.

@deftypevr {Low Level Function Argument} {double *} lower_bound
@deftypevrx {Low Level Function Argument} {double *} upper_bound
@vindex @r{root finding,} lower_bound @r{(low level function argument)}
@vindex @r{root finding,} upper_bound @r{(low level function argument)}
The initial upper and lower bounds of the interval in which to search for a
root. @code{lower_bound} must be less than @code{upper_bound}.

These arguments are modified during execution of the root finding
function; if you need to preserve their initial values, you must make
copies of them. See the third paragraph of this section for the
reasoning behind this behavior.

@end deftypevr

@deftypevr {Low Level Function Argument} {double *} guess
@deftypevrx {Low Level Function Argument} {double *} guess2
@vindex @r{root finding,} guess @r{(low level function argument)}
@vindex @r{root finding,} guess2 @r{(low level function argument)}
One or two initial values for the guess(es) iterated by the root finding
function.

These arguments are modified during execution of the root finding
function; if you need to preserve their initial values, you must make
copies of them. See the third paragraph of this section for the
reasoning behind this behavior.

@end deftypevr


@node Search Stopping Parameters
@section Search Stopping Parameters
@cindex root finding, stopping parameters

The root finding functions (and numerical root finding functions in
general) stop when one of the following conditions is true:

@itemize @bullet
@item
A root has been found to within the user-specified precision.

@item
A user-specified maximum number of iterations has executed.

@item
An error has occured.
@end itemize

Whenever you call a low level root finding function, you must specify
precisely absolute and/or relative tolerances and the maximum number of
iterations.

The stopping criterion decides that two values @math{a} and
@math{b}. with relative tolerance @math{R} and absolute tolerance
@math{A}, are close enough if the following relation is true:

@equation
|a - b| \leq R \min(|a|,|b|) + A 
@end equation

You can set either @math{R} or @math{A} to zero, but be aware that the
library will signal an error if the search moves into an area where both
@math{R} and @math{A} are meaningless; assuming @math{a} and @math{b}
are the endpoints of the region of interest, the following must be true
an error will be returned:

@equation
R \min(|a|,|b|) + A \geq 10 \max(|a|,|b|) \times @{\tt DBL\_EPSILON@} 
@end equation

(We introduce a buffer of @math{10} to protect against roundoff error.)

For the sake of efficient resource use, do not ask for more precision
than you need, especially if your function is costly to evaluate.

@deftypevr {Low Level Function Argument} double abs_epsilon
@vindex @r{root finding,} abs_epsilon @r{(low level function argument)}
The maximum permissible absolute error in root finder answers.

The only static limit on @code{abs_epsilon} is that it must be
positive; see above for other restrictions, however.
@end deftypevr

@deftypevr {Low Level Function Argument} double rel_epsilon
@vindex @r{root finding,} rel_epsilon @r{(low level function argument)}
The maximum permissible relative error in root finder answers.

@code{rel_epsilon} must be greater than or equal to @math{@{\tt
DBL\_EPSILON@} \times 10} (note the buffer factor to protect against
roundoff error). See above for additional non-static restrictions.
@end deftypevr

@deftypevr {Function Argument} {unsigned int} max_iterations
@vindex @r{root finding,} max_iterations @r{(function argument)}
The maximum number of iterations a root finder is allowed to perform.
This must be greater than or equal to 1, as performing a negative number
of iterations is extremely difficult and not doing any iterations is
rather useless.

Do not set @code{max_iterations} too large. If there is a problem,
you want to know about it as soon as possible; you don't want your
program chugging away for many cycles in error.
@end deftypevr

In addition, the root finding functions which extrapolate (Newton's
Method, (@ref{Newtons Method}, and Secant Method, @ref{Secant Method})
accept an additional argument:

@deftypevr {Function Argument} double max_step_size
@vindex @r{root finding,} max_step_size @r{(function argument)}
The maximum step size an extrapolating algorithm is allowed to take.
This is to prevents the algorithm from landing on a place where the test
function's derivative is very small and zooming off to infinity or into
a different solution basin.

@strong{FIXME: talk about minimum value for max_step_size.}

For example, if while solving @math{\sin(x) = 0}, @math{x_n} of Newton's
Method (@pxref{Newtons Method}) landed on @math{1.570700000}
(@math{\pi/2 \approx 1.570796327}), then @math{x_@{n+1@}}
would be approximately @math{-10000}, which is definitely not what we
wanted! We want the root finder to recognize this step as ``too big''
and flag an error.

The alarm bell will ring if the following relation in true:

@equation
|@{@{d@} \over @{dx@}@} f(x)| < |@{@{f(x)@} \over @{\tt max\_step\_size@}@}|
@end equation
@noindent
Note that while Secant Method (@pxref{Secant Method}) does not deal with
derivatives directly, when extrapolating it approximates them
numerically.

Do not set @code{max_step_size} too large; that will defeat its
purpose. In the @math{\sin(x) = 0} example, @math{\pi} would be a good
value for @code{max_step_size}; any step larger than that would
certainly be headed astray. A good understanding of the problem is
especially important for @code{max_step_size}.
@end deftypevr


@node Bisection
@section Bisection
@cindex bisection algorithm for finding roots
@cindex root finding, bisection algorithm

Bisection is a simple and robust method of finding roots of a function
@math{f}; when its arguments are valid, it cannot fail. However, it is
the slowest algorithm provided by the library, and it cannot find roots
of even degree. Its convergence is linear.

One begins the algorithm with an interval which is guaranteed by the
Intermediate Value Theorem to contain a root: where @math{a} and
@math{b} are the endpoints of the interval, @math{f(a)} must differ in
sign from @math{f(b)}. (If you're a bit fuzzy on the Intermediate Value
Theorem, consult any elementary calculus textbook.)

Each iteration, bisection chops its interval in half and discards the
interval which does not contain a root. Once the interval is smaller
than the requested epsilon, iteration stops and the root location is
returned.

@c eps file "roots-bisection.eps"
@iftex
@tex
\input epsf
\medskip
\centerline{\epsfbox{roots-bisection.eps}}
@end tex
@quotation
Four iterations of bisection, where @math{a_n} is @math{n}th position of
the beginning of the interval and @math{b_n} is the @math{n}th position
of the end. The midpoint of each interval is also indicated.
@end quotation
@end iftex
@ifinfo
(Often, root finding algorithms are better explained geometrically. The
@TeX{} version of this documentation contains an image illustrating
bisection.)
@end ifinfo

@deftypefun int gsl_root_bisection (double * @var{root}, double (* @var{f})(double), double * @var{lower_bound}, double * @var{upper_bound}, double @var{rel_epsilon}, double @var{abs_epsilon}, unsigned int @var{max_iterations}, double @var{max_deltay})
@findex @r{root finding,} gsl_root_bisection

Search for a zero of @code{f} using bisection. Returns @code{0} if
successful, @code{-1} on error (@pxref{Root Finder Error
Handling}).

@code{f(*lower_bound)} and @code{f(*upper_bound)} must differ in sign.

Arguments:
@table @code
@item root
A place to store the root location once it is found. @xref{Root Finder
Exit Values}.
@item f
A user defined function to search for a root. @xref{Providing the
Function to Search}.
@item lower_bound@r{, }upper_bound
Lower and upper bounds of the interval to search. @xref{Search Bounds
and Guesses}.
@item rel_epsilon@r{, }abs_epsilon
Maximum permitted relative and absolute error. @xref{Search Stopping
Parameters}.
@item max_iterations
The maximum allowed number of iterations. @xref{Search Stopping
Parameters}.
@item max_deltay
The maximum allowed difference between @code{f(*lower_bound)} and
@code{f(*upper_bound)}. @xref{Search Stopping Parameters}.
@end table

@end deftypefun


@node Brent-Dekker Method
@section Brent-Dekker Method
@cindex brent's method for finding roots
@cindex root finding, brent's method

Brent's method is a simple and robust algorithm of finding roots of a
function @math{f}; when its arguments are valid, it cannot
fail. 

One begins the algorithm with an interval which is guaranteed by the
Intermediate Value Theorem to contain a root: where @math{a} and
@math{b} are the endpoints of the interval, @math{f(a)} must differ in
sign from @math{f(b)}. 

Each iteration, brent's method chops its interval in half and discards the
interval which does not contain a root. Once the interval is smaller
than the requested epsilon, iteration stops and the root location is
returned.

@deftypefun int gsl_root_brent (double * @var{root}, double (* @var{f})(double), double * @var{lower_bound}, double * @var{upper_bound}, double @var{rel_epsilon}, double @var{abs_epsilon}, unsigned int @var{max_iterations})

Search for a zero of @code{f} using Brent's method. Returns @code{0} if
successful, @code{-1} on error (@pxref{Root Finder Error
Handling}).

@code{f(*lower_bound)} and @code{f(*upper_bound)} must differ in sign.

Arguments:
@table @code
@item root
A place to store the root location once it is found. @xref{Root Finder
Exit Values}.
@item f
A user defined function to search for a root. @xref{Providing the
Function to Search}.
@item lower_bound@r{, }upper_bound
Lower and upper bounds of the interval to search. @xref{Search Bounds
and Guesses}.
@item rel_epsilon@r{, }abs_epsilon
Maximum permitted relative and absolute error. @xref{Search Stopping
Parameters}.
@item max_iterations
The maximum allowed number of iterations. @xref{Search Stopping
Parameters}.
@end table

@end deftypefun



@node False Position
@section False Position
@cindex false position algorithm for finding roots
@cindex root finding, false position algorithm

False position is a robust method of finding roots of a function
@math{f}; if its arguments are valid, it cannot fail. However, it cannot
find roots of even degree. Its convergence is linear, but it is usually
faster than bisection.

One begins the algorithm with an interval which is guaranteed by the
Intermediate Value Theorem to contain a root: where @math{a} and
@math{b} are the endpoints of the interval, @math{f(a)} must differ in
sign from @math{f(b)}. (If you're a bit fuzzy on the Intermediate Value
Theorem, consult any elementary calculus textbook.)

Each iteration, false position draws a line between @math{f(a)} and
@math{f(b)}; the @math{x} position where this line crosses the @math{x}
axis is where the interval is split. The part of the interval which
contains the root is taken to be the new interval, and the process is
repeated until one of the following is true:

@equation
|a - b| \leq \varepsilon
@end equation
@equation
a_n - a_@{n-1@} = 0 \;\;\;@{\rm and@}\;\;\; |b_n - b_@{n-1@}| \leq \varepsilon
@end equation
@equation
b_n - b_@{n-1@} = 0 \;\;\;@{\rm and@}\;\;\;|a_n - a_@{n-1@}| \leq \varepsilon
@end equation

@c eps file "roots-false-position.eps"
@iftex
@tex
\input epsf
\medskip
\centerline{\epsfbox{roots-false-position.eps}}
@end tex
@quotation
Several iterations of false position, where @math{a_n} is @math{n}th
position of the beginning of the interval and @math{b_n} is the
@math{n}th position of the end.
@end quotation
@end iftex
@ifinfo
(Often, root finding algorithms are better explained geometrically. The
@TeX{} version of this documentation contains an image illustrating
false position.)
@end ifinfo

@deftypefun int gsl_root_falsepos (double * @var{root}, double (* @var{f})(double), double * @var{lower_bound}, double * @var{upper_bound}, double @var{rel_epsilon}, double @var{abs_epsilon}, unsigned int @var{max_iterations}, double @var{max_deltay})
@findex @r{root finding,} gsl_root_falsepos

Search for a zero of @code{f} using false position. Return @code{0} if
successful, @code{-1} on error (@pxref{Root Finder Error Handling}.

@code{f(*lower_bound)} and @code{f(*upper_bound)} must differ in sign.

Arguments:
@table @code
@item root
A place to store the root location once it is found. @xref{Root Finder
Exit Values}.
@item f
A user defined function to search for a root. @xref{Providing the
Function to Search}.
@item lower_bound@r{, }upper_bound
Lower and upper bounds of the interval to search. @xref{Search Bounds
and Guesses}.
@item rel_epsilon@r{, }abs_epsilon
Maximum permitted relative and absolute error. @xref{Search Stopping
Parameters}.
@item max_iterations
The maximum allowed number of iterations. @xref{Search Stopping
Parameters}.
@item max_deltay
The maximum allowed difference between @code{f(*lower_bound)} and
@code{f(*upper_bound)}. @xref{Search Stopping Parameters}.
@end table

@end deftypefun


@node Secant Method
@section Secant Method
@cindex Secant Method algorithm for finding roots
@cindex root finding, Secant Method algorithm

Secant Method is a somewhat fragile method of finding roots. On single
roots, its convergence is of order @math{(1 + \sqrt 5)/2} (approximately
@math{1.62}). On multiple roots, converges linearly.

One begins the algorithm with two guesses for the value of the root,
@math{g_0} and @math{g_1}. The root may be either inside or outside the
interval defined by @math{g_0} and @math{g_1}.

Each iteration, Secant Method draws a line through @math{f(g_@{n - 1@})}
and @math{f(g_n)}. The @math{x} position where this line crosses the
@math{x} axis becomes @math{g_@{n + 1@}}. @math{g_@{n - 1@}} is
discarded, @math{n} is incremented, and the process is repeated until:

@equation
|g_n - g_@{n-1@}| \leq \varepsilon
@end equation

Note that @math{g_@{n + 1@}} may be obtained by either interpolation or
extrapolation and that Secant Method cannot fail during interpolation.

Secant Method breaks in the same situations that Newton's Method does,
though it is somewhat less sensitive. (@xref{Newtons Method}.)

@c eps file "roots-secant-method.eps"
@iftex
@tex
\input epsf
\medskip
\centerline{\epsfbox{roots-secant-method.eps}}
@end tex
@quotation
Several iterations of Secant Method, where @math{g_n} is the @math{n}th
guess.
@end quotation
@end iftex
@ifinfo
(Often, root finding algorithms are better explained geometrically. The
@TeX{} version of this documentation contains an image illustrating
Secant Method.)
@end ifinfo

@deftypefun int gsl_root_secant (double * @var{root}, double (* @var{f})(double), double * @var{guess}, double * @var{guess2}, double @var{epsilon}, unsigned int @var{max_iterations}, double @var{max_step_size})
@findex @r{root finding,} gsl_root_secant

Search for a zero of @code{f} using Secant Method, with @code{*guess}
and @code{*guess2} being the guesses.

arguments. @xref{Root Finder Error Handling}, for a discussion of possible
error codes.

@end deftypefun


@node Newtons Method
@section Newtons Method
@cindex Newton's Method algorithm for finding roots
@cindex root finding, Newton's Method algorithm

Newton's Method is a fast but somewhat fragile method of finding roots.
On single roots, it converges quadratically; however, on multiple roots
it converges linearly.

One begins the algorithm with one guess @math{g} for the value of the
root. Each iteration, Newton's Method draws a line tangent to @math{f}
(the function whose root you are searching for); the @math{x} position
where this line crosses the @math{x} axis becomes the new @math{g}. The
process is repeated until:

@equation
|g_n - g_@{n-1@}| \leq \varepsilon
@end equation


@c eps file "roots-newtons-method.eps"
@iftex
@tex
\input epsf
\medskip
\centerline{\epsfbox{roots-newtons-method.eps}}
@end tex
@quotation
Several iterations of Newton's Method, where @math{g_n} is the
@math{n}th guess.
@end quotation
@end iftex
@ifinfo
(Often, root finding algorithms are better explained geometrically. The
@TeX{} version of this documentation contains an image illustrating
Newton's Method.)
@end ifinfo

@deftypefun int gsl_root_newton (double * @var{root}, void (* @var{fdf})(double *, double *, double, int, int), double * @var{guess}, double @var{epsilon}, unsigned int @var{max_iterations}, double @var{max_step_size})
@findex @r{root finding,} gsl_root_newton

Search for a zero of @code{f} using Newton's Method, with @code{*guess}
being the guess.

@xref{Root Finder Error Handling}, for a discussion of possible
error codes.

@end deftypefun

@node Root Finder Error Handling
@section Root Finder Error Handling
@cindex root finding, errors

When successful, the root finding functions return @code{0}; on error,
they return @code{-1} and set the global variable @code{gsl_errno}
to a diagnostic value. (@xref{Error handling in GSL}, for a general
discussion of GSL error handling.)

When using low-level functions, you can examine @code{*guess},
@code{*guess2}, @code{*lower_bound}, or @code{*upper_bound}
(@pxref{Search Bounds and Guesses}) to help determine why a root finder
failed.

@set llo @i{[Low Level Only]}
The root finders can set @code{gsl_errno} to the following macros.
Some errors can only be encountered by low level functions; they are
marked by @value{llo}.

@table @code
@item GSL_EINVAL
One or more of the input arguments is invalid because at least one of
these conditions is true:

@itemize @bullet
@item 
@value{llo} @code{max_iterations} is equal to 0. @xref{Search
Stopping Parameters}.

@item
The lower bound of the search interval is not less than the upper bound.

@item
You supplied a pointer argument which was null.

@item
@math{f(lower\_bound)} and @math{f(upper\_bound)} do not differ in sign,
and the function that you are using requires that they do.

@end itemize

@item GSL_EBADFUNC
The function under search (or its derivative) did not return a valid
number when it was called by the the root finder. (Instead, it returned
@code{NAN} or @code{INF}.)

@item GSL_ERUNAWAY
@value{llo} A root finder tried to take a step larger than
@code{max_step_size} (@pxref{Search Stopping Parameters}). This
happens when an extrapolating algorithm lands on a place where the
derivative is too small.

@item GSL_EMAXITER
The number of iterations executed exceeded @code{max_iterations}
(@pxref{Search Stopping Parameters}).

@item GSL_EBADTOL
@value{llo} You specified an invalid error tolerance in one or more of
the following ways (@pxref{Search Stopping Parameters}):

@itemize @bullet
@item
@code{rel_epsilon} was too small.

@item
@code{rel_epsilon} and @code{abs_epsilon} were both zero.

@item
@code{rel_epsilon} was zero, and the search converged to a place too
far from zero for @code{abs_epsilon} to be useful.

@item
@code{abs_epsilon} was zero, and the search converged to a place too
close to zero for @code{rel_epsilon} to be useful.

@item
@strong{FIXME: add stuff for delta.}
@end itemize
   
@item GSL_EZERODIV
@value{llo} A function detected that any further iterations would result
in division by zero. This most often happens when Newton's Method
(@pxref{Newtons Method}) or Secant Method (@pxref{Secant Method}) lands
on an extremum.
@end table


